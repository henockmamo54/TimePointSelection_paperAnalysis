{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "from scipy.stats import gaussian_kde\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import pingouin as pg\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. RateConst Reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllRateInfo(file):   \n",
    "    res=pd.DataFrame()\n",
    "    try:\n",
    "        temp=pd.read_csv(file)\n",
    "        temp=temp.dropna()\n",
    "        temp['Protein']=file.split('\\\\')[-1].replace('.RateConst.csv','')\n",
    "        res=pd.concat([res,temp])\n",
    "    except Exception as exp:\n",
    "        return res\n",
    "    \n",
    "    return res\n",
    "def getAllRate(data_path):\n",
    "    results = Parallel(n_jobs=-1)(delayed(getAllRateInfo)(file) for file in [os.path.join(data_path,x) for x in os.listdir(data_path) if '.RateConst.csv' in x  ]) \n",
    "    all_data=pd.concat(results)\n",
    "    all_data=all_data.reset_index(drop=True)\n",
    "    all_data.columns=[x.strip() for x in all_data.columns]\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Quant File Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_n_merge(skip,file):\n",
    "    file_data=pd.read_csv(file,skiprows=skip,index_col=False)\n",
    "    file_data.columns=[x.strip() for x in file_data.columns]\n",
    "    isparsed=(set(['Peptide', 'UniqueToProtein', 'Exchangeable Hydrogens', 'Charge',\n",
    "       'm/z(Sequence)', 'M0', 'M1', 'M2', 'M3', 'M4']).issubset(set(file_data.columns)))\n",
    "    isparsed=isparsed and file_data.shape[0]>0    \n",
    "    if isparsed:\n",
    "        file_data['Protein']=file.split('\\\\')[-1].replace('.Quant.csv','') \n",
    "        return [isparsed,file_data]\n",
    "    else:\n",
    "        return [isparsed,None]\n",
    "def get_df_all_quant_files(file):\n",
    "    res=read_n_merge(1,file)\n",
    "    all_data=None\n",
    "    if res[0]: all_data=res[1]\n",
    "    else: all_data=read_n_merge(3,file)[1]\n",
    "    return all_data\n",
    "\n",
    "def getquantfile(data_path):\n",
    "    results = Parallel(n_jobs=-1)(delayed(get_df_all_quant_files)(file) for file in [os.path.join(data_path,x) for x in os.listdir(data_path) if '.Quant.csv' in x  ])\n",
    "    all_data=pd.concat(results)\n",
    "    all_data=all_data.reset_index(drop=True)\n",
    "    all_data.columns=[x.strip() for x in all_data.columns]\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data source & path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "organ=\"liver\"\n",
    "# organ=\"heart\"\n",
    "# organ=\"muscle\"\n",
    "data_path=r'C:\\Workplace\\Python\\AnalysisForThePaper\\NEH\\d2ome_output\\liverpool_liver'\n",
    "# data_path=r'C:\\Workplace\\Python\\AnalysisForThePaper\\NEH\\d2ome_output\\liverpool_heart'\n",
    "# data_path=r'H:\\Warehouse\\Data\\DataUsedForPublication\\Partial IsotopeProfile paper data used for publication\\liverpool_CI\\muscle'\n",
    "\n",
    "\n",
    "data_quant=getquantfile(data_path)\n",
    "data_rate=getAllRate(data_path)\n",
    "data_rate=data_rate[(data_rate.Rsquared!=' -nan(ind)')&(data_rate.Rsquared!=' ')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. merge quant and rate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18510, 219)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged=pd.merge(data_quant,\n",
    "                data_rate,\n",
    "                left_on=['Protein','Peptide','Charge'],\n",
    "                right_on=['Protein','Peptides','Charge'])\n",
    "merged=merged.reset_index(drop=True)\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw,ph=0.046,1.5574E-4\n",
    "# rsquared= 0.99\n",
    "maxrate=math.log(2)\n",
    "exp_time=[0 ,1 ,2 ,3 ,6 ,7 ,9 ,13,16,21,24,31]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17344, 219)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged=merged[#(merged.Rsquared.astype('float')>=rsquared) &\n",
    "              (merged.RateConstants< math.log(2))]\n",
    "merged=merged.reset_index(drop=True)\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_I0_t(I0_0,I0_asymp,k,t):\n",
    "    return I0_asymp + (I0_0-I0_asymp)*math.exp(-k*t)\n",
    "\n",
    "def get_I0_asmyp(I0_0,neh):\n",
    "    return I0_0*( (1 - pw/(1-ph))**neh )\n",
    "\n",
    "def get_I0_exp(index,suffix):\n",
    "    _sum=float(float(merged.loc[index,f'I0{suffix}'])+float(merged.loc[index,f'I1{suffix}'])+float(merged.loc[index,f'I2{suffix}'])+float(merged.loc[index,f'I3{suffix}'])+\n",
    "                        float(merged.loc[index,f'I4{suffix}'])+float(merged.loc[index,f'I5{suffix}']))\n",
    "    if _sum==0: return None\n",
    "    else: return float(merged.loc[index,f'I0{suffix}'])/_sum\n",
    "\n",
    "def getNewKestimate(M0_0,I0_0_exp,I0_asymp,t,I0_t_exp,numberofTerms): \n",
    "        \n",
    "    base=(I0_0_exp-I0_t_exp)/(M0_0-I0_asymp)    \n",
    "    new_kt= sum([ (base**i)/i for i in range(1,numberofTerms+1)])     \n",
    "    new_k=new_kt/t    \n",
    "    return new_k\n",
    "\n",
    "\n",
    "def getNewKestimateByIndex(time,numberofterms_1,index,numberofterms_10):\n",
    "        \n",
    "        time_index=exp_time.index(time)\n",
    "        suffix=f\".{time_index}\"  \n",
    "        # print('time',time,time_index)\n",
    "                                              \n",
    "        if merged.loc[index,f'I0{suffix}'] == ' ' or merged.loc[index,f'I0'] == ' ': \n",
    "            return None            \n",
    "        \n",
    "        I0_0_exp= get_I0_exp(index,\"\")\n",
    "        I0_t_exp=get_I0_exp(index,suffix)\n",
    "        \n",
    "        if I0_0_exp == None or I0_t_exp ==None or  I0_t_exp >  I0_0_exp: \n",
    "            return None\n",
    "\n",
    "        M0_0=float(merged.loc[index,f'M0'])/100\n",
    "        k=float(merged.loc[index,f'RateConstants'])\n",
    "        I0_asymp=M0_0*( (1 - pw/(1-ph))**merged.loc[index,f'Exchangeable Hydrogens'] ) \n",
    "        i0_t_theo= I0_asymp + (M0_0-I0_asymp)*math.exp(-k*time)     \n",
    "        \n",
    "        exp_fsr= (I0_0_exp-I0_t_exp)/(M0_0-I0_asymp)\n",
    "        # print(exp_fsr, (I0_0_exp-I0_t_exp),(M0_0-I0_asymp),\"==>\",(I0_0_exp,I0_t_exp),(M0_0,I0_asymp) )\n",
    "        if exp_fsr > 1: return None\n",
    "        exp_kt= -math.log( 1 - exp_fsr) \n",
    "        d2ome_kt=k*time\n",
    "        \n",
    "        error=   abs(exp_kt - d2ome_kt)/d2ome_kt\n",
    "        \n",
    "        \n",
    "\n",
    "        return[merged.loc[index,'Protein'],\n",
    "               merged.loc[index,'Peptide'],\n",
    "               merged.loc[index,'Charge'],                \n",
    "                merged.loc[index,f'Exchangeable Hydrogens'],\n",
    "                M0_0,I0_0_exp,\n",
    "                I0_asymp,\n",
    "                I0_t_exp,i0_t_theo,k,exp_kt/time] +[getNewKestimate(M0_0,I0_0_exp,I0_asymp,time,I0_t_exp,numberofterms_1),\n",
    "                                                    getNewKestimate(M0_0,I0_0_exp,I0_asymp,time,I0_t_exp,numberofterms_10),error]\n",
    "        \n",
    "def computeAllNewRates(_time,_numberOfTerms,_numberOfTerms10):\n",
    "    # res = Parallel(n_jobs=-1)(delayed(getNewKestimateByIndex)(_time,_numberOfTerms,index) for index in range(merged.shape[0]))\n",
    "    res=[getNewKestimateByIndex(_time,_numberOfTerms,index,_numberOfTerms10) for index in range(merged.shape[0])]\n",
    "    res=pd.DataFrame([r for r in res if r!=None])\n",
    "    res.columns=['Protein','Peptide','Charge',\"NEH\",\"M0\",\"I0_0_exp\",\"I0_asmp\",'i0_t_exp','i0_t_theo','d2ome_k','k_sol','new_k_1','new_k_10','error']\n",
    "    return res\n",
    "\n",
    "    \n",
    "def getStat(x,y):\n",
    "    \n",
    "    r=np.corrcoef(x,y)\n",
    "    rd_k= (x - y)/x\n",
    "    # # label=f\"r={int(1000*r[0][1])/1000},Î¼ = {int(100*np.mean(rd_k))/100}, median = {int(100*np.median(rd_k))/100}, sd = {int(100*np.std(rd_k))/100}\"\n",
    "    # label=[int(1000*r[0][1])/1000 , int(100*np.mean(rd_k))/100,int(100*np.median(rd_k))/100,int(100*np.std(rd_k))/100]    \n",
    "        \n",
    "    result=pg.corr(x, y, method='pearson')[['CI95%']].reset_index(drop=True)\n",
    "    ci=result.loc[0,:][0]\n",
    "    \n",
    "    print(f\"{r[0][1]:.2f} [{ci[0]:.2f},{ci[1]:.2f}]\")\n",
    "    \n",
    "    label=[f\"{r[0][1]:.2f} [{ci[0]:.2f},{ci[1]:.2f}]\" , \n",
    "           int(100*np.mean(rd_k))/100,int(100*np.median(rd_k))/100,int(100*np.std(rd_k))/100]\n",
    "    \n",
    "        \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=np.random.normal(0,1E5,100)\n",
    "# y=np.random.normal(0,1E5,100)\n",
    "# x=getStat(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Prepare all new k values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17344, 219)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allmerged=merged.copy()\n",
    "allmerged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|ââ        | 1/7 [00:29<02:54, 29.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80 [0.79,0.81]\n",
      "0.79 [0.78,0.80]\n",
      "_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|âââ       | 2/7 [00:57<02:22, 28.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88 [0.88,0.89]\n",
      "0.86 [0.86,0.87]\n",
      "_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|âââââ     | 3/7 [01:25<01:53, 28.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88 [0.87,0.88]\n",
      "0.86 [0.85,0.86]\n",
      "_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|ââââââ    | 4/7 [01:54<01:26, 28.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80 [0.79,0.80]\n",
      "0.79 [0.79,0.80]\n",
      "_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|ââââââââ  | 5/7 [02:23<00:57, 28.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76 [0.75,0.77]\n",
      "0.76 [0.76,0.77]\n",
      "_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|âââââââââ | 6/7 [02:49<00:27, 27.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54 [0.53,0.56]\n",
      "0.56 [0.55,0.58]\n",
      "_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 7/7 [03:14<00:00, 27.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45 [0.43,0.47]\n",
      "0.47 [0.45,0.49]\n",
      "_time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all=[]\n",
    "for _time in tqdm([1 ,2 ,3 ,6 ,7,13,16]):\n",
    "# for _time in tqdm([6 ,7,16]):    \n",
    "    for _rsquared in [0.9][::-1]:\n",
    "                        \n",
    "            try:                \n",
    "                merged=allmerged.copy()\n",
    "                merged=merged[(merged.Rsquared.astype('float')>=_rsquared)]\n",
    "                merged=merged.reset_index(drop=True)\n",
    "\n",
    "\n",
    "                res=computeAllNewRates(_time,1,10)\n",
    "\n",
    "                res=res[(res.d2ome_k.astype('float')>=0)]\n",
    "                res=res[(res.new_k_1.astype('float')>=0)]\n",
    "                res=res[(res.new_k_10.astype('float')>=0)]\n",
    "                res=res[(res.k_sol.astype('float')>=0)]\n",
    "\n",
    "                res=res[abs(res.M0 -res.I0_0_exp)/res.M0 <=0.1]\n",
    "                \n",
    "                val=[_time,res.shape[0]]+ getStat(res.d2ome_k,res.k_sol)+ getStat(res.d2ome_k,res.new_k_1)\n",
    "                all.append(val)\n",
    "                print(f\"_time\")\n",
    "\n",
    " \n",
    "            except Exception as exp:\n",
    "                print(exp)\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "all=pd.DataFrame(all)\n",
    "all.columns=['Labeling duration','Number of Peptides','Pearson correlation coefficient','Relative difference mean','Relative difference median','Relative difference SD',\n",
    "             'Pearson correlation coefficient','Relative difference mean','Relative difference median','Relative difference SD']\n",
    "all.to_csv(f\"{organ}_stat.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "henock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
