{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "from scipy.stats import gaussian_kde\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import pingouin as pg\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. RateConst Reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllRateInfo(file):   \n",
    "    res=pd.DataFrame()\n",
    "    try:\n",
    "        temp=pd.read_csv(file)\n",
    "        temp=temp.dropna()\n",
    "        temp['Protein']=file.split('\\\\')[-1].replace('.RateConst.csv','')\n",
    "        res=pd.concat([res,temp])\n",
    "    except Exception as exp:\n",
    "        return res\n",
    "    \n",
    "    return res\n",
    "def getAllRate(data_path):\n",
    "    results = Parallel(n_jobs=-1)(delayed(getAllRateInfo)(file) for file in [os.path.join(data_path,x) for x in os.listdir(data_path) if '.RateConst.csv' in x  ]) \n",
    "    all_data=pd.concat(results)\n",
    "    all_data=all_data.reset_index(drop=True)\n",
    "    all_data.columns=[x.strip() for x in all_data.columns]\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Quant File Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_n_merge(skip,file):\n",
    "    file_data=pd.read_csv(file,skiprows=skip,index_col=False)\n",
    "    file_data.columns=[x.strip() for x in file_data.columns]\n",
    "    isparsed=(set(['Peptide', 'UniqueToProtein', 'Exchangeable Hydrogens', 'Charge',\n",
    "       'm/z(Sequence)', 'M0', 'M1', 'M2', 'M3', 'M4']).issubset(set(file_data.columns)))\n",
    "    isparsed=isparsed and file_data.shape[0]>0    \n",
    "    if isparsed:\n",
    "        file_data['Protein']=file.split('\\\\')[-1].replace('.Quant.csv','') \n",
    "        return [isparsed,file_data]\n",
    "    else:\n",
    "        return [isparsed,None]\n",
    "def get_df_all_quant_files(file):\n",
    "    res=read_n_merge(1,file)\n",
    "    all_data=None\n",
    "    if res[0]: all_data=res[1]\n",
    "    else: all_data=read_n_merge(3,file)[1]\n",
    "    return all_data\n",
    "\n",
    "def getquantfile(data_path):\n",
    "    results = Parallel(n_jobs=-1)(delayed(get_df_all_quant_files)(file) for file in [os.path.join(data_path,x) for x in os.listdir(data_path) if '.Quant.csv' in x  ])\n",
    "    all_data=pd.concat(results)\n",
    "    all_data=all_data.reset_index(drop=True)\n",
    "    all_data.columns=[x.strip() for x in all_data.columns]\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data source & path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organ=\"liver\"\n",
    "organ=\"heart\"\n",
    "# organ=\"muscle\"\n",
    "# data_path=r'C:\\Workplace\\Python\\AnalysisForThePaper\\NEH\\d2ome_output\\liverpool_liver'\n",
    "data_path=r'C:\\Workplace\\Python\\AnalysisForThePaper\\NEH\\d2ome_output\\liverpool_heart'\n",
    "# data_path=r'H:\\Warehouse\\Data\\DataUsedForPublication\\Partial IsotopeProfile paper data used for publication\\liverpool_CI\\muscle'\n",
    "\n",
    "\n",
    "data_quant=getquantfile(data_path)\n",
    "data_rate=getAllRate(data_path)\n",
    "data_rate=data_rate[(data_rate.Rsquared!=' -nan(ind)')&(data_rate.Rsquared!=' ')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. merge quant and rate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13520, 217)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged=pd.merge(data_quant,\n",
    "                data_rate,\n",
    "                left_on=['Protein','Peptide','Charge'],\n",
    "                right_on=['Protein','Peptides','Charge'])\n",
    "merged=merged.reset_index(drop=True)\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw,ph=0.046,1.5574E-4\n",
    "# rsquared= 0.99\n",
    "maxrate=math.log(2)\n",
    "exp_time=[0 ,1 ,2 ,3 ,6 ,7 ,9 ,13,16,21,24,31]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13240, 217)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged=merged[#(merged.Rsquared.astype('float')>=rsquared) &\n",
    "              (merged.RateConstants< math.log(2))]\n",
    "merged=merged.reset_index(drop=True)\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_I0_t(I0_0,I0_asymp,k,t):\n",
    "    return I0_asymp + (I0_0-I0_asymp)*math.exp(-k*t)\n",
    "\n",
    "def get_I0_asmyp(I0_0,neh):\n",
    "    return I0_0*( (1 - pw/(1-ph))**neh )\n",
    "\n",
    "def get_I0_exp(index,suffix):\n",
    "    _sum=float(float(merged.loc[index,f'I0{suffix}'])+float(merged.loc[index,f'I1{suffix}'])+float(merged.loc[index,f'I2{suffix}'])+float(merged.loc[index,f'I3{suffix}'])+\n",
    "                        float(merged.loc[index,f'I4{suffix}'])+float(merged.loc[index,f'I5{suffix}']))\n",
    "    if _sum==0: return None\n",
    "    else: return float(merged.loc[index,f'I0{suffix}'])/_sum\n",
    "\n",
    "def getNewKestimate(M0_0,I0_0_exp,I0_asymp,t,I0_t_exp,numberofTerms): \n",
    "        \n",
    "    base=(I0_0_exp-I0_t_exp)/(M0_0-I0_asymp)    \n",
    "    new_kt= sum([ (base**i)/i for i in range(1,numberofTerms+1)])     \n",
    "    new_k=new_kt/t    \n",
    "    return new_k\n",
    "\n",
    "\n",
    "def getNewKestimateByIndex(time,numberofterms_1,index,numberofterms_10):\n",
    "        \n",
    "        time_index=exp_time.index(time)\n",
    "        suffix=f\".{time_index}\"  \n",
    "        # print('time',time,time_index)\n",
    "                                              \n",
    "        if merged.loc[index,f'I0{suffix}'] == ' ' or merged.loc[index,f'I0'] == ' ': \n",
    "            return None            \n",
    "        \n",
    "        I0_0_exp= get_I0_exp(index,\"\")\n",
    "        I0_t_exp=get_I0_exp(index,suffix)\n",
    "        \n",
    "        if I0_0_exp == None or I0_t_exp ==None or  I0_t_exp >  I0_0_exp: \n",
    "            return None\n",
    "\n",
    "        M0_0=float(merged.loc[index,f'M0'])/100\n",
    "        k=float(merged.loc[index,f'RateConstants'])\n",
    "        I0_asymp=M0_0*( (1 - pw/(1-ph))**merged.loc[index,f'Exchangeable Hydrogens'] ) \n",
    "        i0_t_theo= I0_asymp + (M0_0-I0_asymp)*math.exp(-k*time)     \n",
    "        \n",
    "        exp_fsr= (I0_0_exp-I0_t_exp)/(M0_0-I0_asymp)\n",
    "        # print(exp_fsr, (I0_0_exp-I0_t_exp),(M0_0-I0_asymp),\"==>\",(I0_0_exp,I0_t_exp),(M0_0,I0_asymp) )\n",
    "        if exp_fsr > 1: return None\n",
    "        exp_kt= -math.log( 1 - exp_fsr) \n",
    "        d2ome_kt=k*time\n",
    "        \n",
    "        error=   abs(exp_kt - d2ome_kt)/d2ome_kt\n",
    "        \n",
    "        \n",
    "\n",
    "        return[merged.loc[index,'Protein'],\n",
    "               merged.loc[index,'Peptide'],\n",
    "               merged.loc[index,'Charge'],                \n",
    "                merged.loc[index,f'Exchangeable Hydrogens'],\n",
    "                M0_0,I0_0_exp,\n",
    "                I0_asymp,\n",
    "                I0_t_exp,i0_t_theo,k,exp_kt/time] +[getNewKestimate(M0_0,I0_0_exp,I0_asymp,time,I0_t_exp,numberofterms_1),\n",
    "                                                    getNewKestimate(M0_0,I0_0_exp,I0_asymp,time,I0_t_exp,numberofterms_10),error]\n",
    "        \n",
    "def computeAllNewRates(_time,_numberOfTerms,_numberOfTerms10):\n",
    "    # res = Parallel(n_jobs=-1)(delayed(getNewKestimateByIndex)(_time,_numberOfTerms,index) for index in range(merged.shape[0]))\n",
    "    res=[getNewKestimateByIndex(_time,_numberOfTerms,index,_numberOfTerms10) for index in range(merged.shape[0])]\n",
    "    res=pd.DataFrame([r for r in res if r!=None])\n",
    "    res.columns=['Protein','Peptide','Charge',\"NEH\",\"M0\",\"I0_0_exp\",\"I0_asmp\",'i0_t_exp','i0_t_theo','d2ome_k','k_sol','new_k_1','new_k_10','error']\n",
    "    return res\n",
    "  \n",
    "def getStat(x,y):\n",
    "    \n",
    "    r=np.corrcoef(x,y)\n",
    "    rd_k= (x - y)/x\n",
    "    # # label=f\"r={int(1000*r[0][1])/1000},μ = {int(100*np.mean(rd_k))/100}, median = {int(100*np.median(rd_k))/100}, sd = {int(100*np.std(rd_k))/100}\"\n",
    "    # label=[int(1000*r[0][1])/1000 , int(100*np.mean(rd_k))/100,int(100*np.median(rd_k))/100,int(100*np.std(rd_k))/100]    \n",
    "        \n",
    "    result=pg.corr(x, y, method='pearson')[['CI95%']].reset_index(drop=True)\n",
    "    ci=result.loc[0,:][0]\n",
    "    \n",
    "    print(f\"{r[0][1]:.2f} [{ci[0]:.2f},{ci[1]:.2f}]\")\n",
    "    \n",
    "    label=[f\"{r[0][1]:.2f} [{ci[0]:.2f},{ci[1]:.2f}]\" , \n",
    "           int(100*np.mean(rd_k))/100,int(100*np.median(rd_k))/100,int(100*np.std(rd_k))/100]\n",
    "    \n",
    "        \n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Prepare all new k values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13240, 217)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allmerged=merged.copy()\n",
    "allmerged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [00:26<02:39, 26.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'pg' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2/7 [00:45<01:50, 22.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'pg' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [01:04<01:21, 20.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'pg' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 4/7 [01:22<00:58, 19.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'pg' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [01:40<00:38, 19.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'pg' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 6/7 [01:59<00:19, 19.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'pg' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [02:17<00:00, 19.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'pg' is not defined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all=[]\n",
    "for _time in tqdm([1 ,2 ,3 ,6 ,7,13,16]):\n",
    "# for _time in tqdm([6 ,7,16]):    \n",
    "    for _rsquared in [0.9][::-1]:\n",
    "                        \n",
    "            try:                \n",
    "                merged=allmerged.copy()\n",
    "                merged=merged[(merged.Rsquared.astype('float')>=_rsquared)]\n",
    "                merged=merged.reset_index(drop=True)\n",
    "\n",
    "\n",
    "                res=computeAllNewRates(_time,1,10)\n",
    "\n",
    "                res=res[(res.d2ome_k.astype('float')>=0)]\n",
    "                res=res[(res.new_k_1.astype('float')>=0)]\n",
    "                res=res[(res.new_k_10.astype('float')>=0)]\n",
    "                res=res[(res.k_sol.astype('float')>=0)]\n",
    "\n",
    "                res=res[abs(res.M0 -res.I0_0_exp)/res.M0 <=0.1]\n",
    "                \n",
    "                val=[_time,res.shape[0]]+ getStat(res.d2ome_k,res.k_sol)+ getStat(res.d2ome_k,res.new_k_1)\n",
    "                all.append(val)\n",
    "                print(f\"_time\")\n",
    "\n",
    " \n",
    "            except Exception as exp:\n",
    "                print(exp)\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 0 elements, new values have 10 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[38;5;28mall\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mall\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabeling duration\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of Peptides\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPearson correlation coefficient\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRelative difference mean\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRelative difference median\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRelative difference SD\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m              \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPearson correlation coefficient\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRelative difference mean\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRelative difference median\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRelative difference SD\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mall\u001b[39m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morgan\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_stat.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\henock\\Lib\\site-packages\\pandas\\core\\generic.py:6313\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   6311\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   6312\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[1;32m-> 6313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[0;32m   6314\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   6315\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\henock\\Lib\\site-packages\\pandas\\core\\generic.py:814\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    810\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    813\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 814\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mset_axis(axis, labels)\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\henock\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:238\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_set_axis(axis, new_labels)\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\henock\\Lib\\site-packages\\pandas\\core\\internals\\base.py:98\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 0 elements, new values have 10 elements"
     ]
    }
   ],
   "source": [
    "all=pd.DataFrame(all)\n",
    "all.columns=['Labeling duration','Number of Peptides','Pearson correlation coefficient','Relative difference mean','Relative difference median','Relative difference SD',\n",
    "             'Pearson correlation coefficient','Relative difference mean','Relative difference median','Relative difference SD']\n",
    "all.to_csv(f\"{organ}_stat.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "henock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
